{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Generator\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "import whisper\n",
    "import IPython.display as ipd\n",
    "\n",
    "from transformers import GPT2TokenizerFast\n",
    "import model2\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dims', 'model_state_dict'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_mels': 80,\n",
       " 'n_vocab': 51865,\n",
       " 'n_audio_ctx': 1500,\n",
       " 'n_audio_state': 384,\n",
       " 'n_audio_head': 6,\n",
       " 'n_audio_layer': 4,\n",
       " 'n_text_ctx': 448,\n",
       " 'n_text_state': 384,\n",
       " 'n_text_head': 6,\n",
       " 'n_text_layer': 4}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tiny_path = Path(\"~/.cache/whisper/tiny.pt\").expanduser()\n",
    "with open(tiny_path, \"rb\") as f:\n",
    "    checkpoint = torch.load(f)\n",
    "ipd.display(checkpoint.keys())\n",
    "ipd.display(checkpoint[\"dims\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori = whisper.load_model(\"tiny\", device=\"cpu\").eval()  # original model loading\n",
    "model_dims = model2.ModelDimensions(**checkpoint[\"dims\"])\n",
    "modded = model2.Whisper(model_dims).eval()\n",
    "modded.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "scripted = torch.jit.script(modded).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple encoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = whisper.load_audio(\"tests/jfk.flac\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "mel = whisper.log_mel_spectrogram(audio).unsqueeze(0)\n",
    "\n",
    "# # detect the spoken language\n",
    "# _, probs = model.detect_language(mel)\n",
    "# print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# # decode the audio\n",
    "# options = whisper.DecodingOptions()\n",
    "# result = whisper.decode(model, mel, options)\n",
    "\n",
    "# # print the recognized text\n",
    "# print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ori_encoded = ori.encoder(mel)\n",
    "modded_encoded = modded.encoder(mel)\n",
    "scripted_encoded = scripted.encoder(mel)\n",
    "\n",
    "print(torch.allclose(ori_encoded, modded_encoded))\n",
    "print(torch.allclose(ori_encoded, scripted_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple decoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50359, 50363]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is <|startoftranscript|><|en|><|transcribe|><|notimestamps|> from gpt2 tokenizer\n",
    "tokens = torch.tensor([50258, 50259, 50359, 50363]).unsqueeze(0)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ori_decoded = ori.decoder(tokens, ori_encoded)\n",
    "modded_decoded = modded.decoder(tokens, ori_encoded, {})\n",
    "scripted_decoded = scripted.decoder(tokens, ori_encoded, {})\n",
    "\n",
    "print(torch.allclose(ori_decoded, modded_decoded))\n",
    "print(torch.allclose(ori_decoded, scripted_decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummy(nn.Module):\n",
    "    \n",
    "    def __init__(self, keygen: Generator) -> None:\n",
    "        super().__init__()\n",
    "        self.unique_num = next(keygen)\n",
    "        self.unique_num = next(keygen)\n",
    "        self.lin = nn.Linear(4, 4)\n",
    "    \n",
    "    def forward(self, x: Tensor, cache: dict[int, Tensor]):\n",
    "        if self.unique_num not in cache:\n",
    "            cache[self.unique_num] = self.lin(x)\n",
    "        return cache[self.unique_num]\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def generate(self, x: Tensor):\n",
    "        print(self.unique_num)\n",
    "        cache: dict[int, Tensor] = {}\n",
    "        a = self.forward(x, cache)\n",
    "        b = self.forward(x*2, cache)\n",
    "        return a-b\n",
    "\n",
    "keygen = itertools.count()\n",
    "dummy = Dummy(keygen)\n",
    "sdummy = torch.jit.script(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.generate(torch.randn(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdummy.generate(torch.randn(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'bool' as child module 'training' (torch.nn.Module or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/evan/Documents/whisper-torchscript/tests.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evan/Documents/whisper-torchscript/tests.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/evan/Documents/whisper-torchscript/tests.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m net \u001b[39m=\u001b[39m Net()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/evan/Documents/whisper-torchscript/tests.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m net\u001b[39m.\u001b[39;49meval()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1858\u001b[0m, in \u001b[0;36mModule.eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval\u001b[39m(\u001b[39mself\u001b[39m: T) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m   1843\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sets the module in evaluation mode.\u001b[39;00m\n\u001b[1;32m   1844\u001b[0m \n\u001b[1;32m   1845\u001b[0m \u001b[39m    This has any effect only on certain modules. See documentations of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1856\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1858\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1837\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mode, \u001b[39mbool\u001b[39m):\n\u001b[1;32m   1836\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mtraining mode is expected to be boolean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1837\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m mode\n\u001b[1;32m   1838\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m   1839\u001b[0m     module\u001b[39m.\u001b[39mtrain(mode)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1242\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[39melif\u001b[39;00m modules \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1241\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1242\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot assign \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m as child module \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1243\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39m(torch.nn.Module or None expected)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1244\u001b[0m                         \u001b[39m.\u001b[39mformat(torch\u001b[39m.\u001b[39mtypename(value), name))\n\u001b[1;32m   1245\u001b[0m     modules[name] \u001b[39m=\u001b[39m value\n\u001b[1;32m   1246\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot assign 'bool' as child module 'training' (torch.nn.Module or None expected)"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.training = nn.Linear(5, 4)  # hmm\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c788065d0627783e03f01588c616fdc081ccf79059243dc851e48ed3fc07eef9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
