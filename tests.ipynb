{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Generator\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "import whisper\n",
    "import IPython.display as ipd\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "from transformers import GPT2TokenizerFast\n",
    "import model2\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dims', 'model_state_dict'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_mels': 80,\n",
       " 'n_vocab': 51865,\n",
       " 'n_audio_ctx': 1500,\n",
       " 'n_audio_state': 512,\n",
       " 'n_audio_head': 8,\n",
       " 'n_audio_layer': 6,\n",
       " 'n_text_ctx': 448,\n",
       " 'n_text_state': 512,\n",
       " 'n_text_head': 8,\n",
       " 'n_text_layer': 6}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whisper_path = Path(\"~/.cache/whisper/base.pt\").expanduser()  # download the weights first using official whisper\n",
    "with open(whisper_path, \"rb\") as f:\n",
    "    checkpoint = torch.load(f)\n",
    "ipd.display(checkpoint.keys())\n",
    "ipd.display(checkpoint[\"dims\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori = whisper.load_model(\"base\", device=\"cpu\").eval()  # original model loading\n",
    "model_dims = model2.ModelDimensions(**checkpoint[\"dims\"])\n",
    "modded = model2.Whisper(model_dims).eval()\n",
    "modded.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "scripted = torch.jit.script(modded).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple encoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = whisper.load_audio(\"tests/jfk.flac\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "mel = whisper.log_mel_spectrogram(audio).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_encoded = ori.encoder(mel)\n",
    "modded_encoded = modded.encoder(mel)\n",
    "scripted_encoded = scripted.encoder(mel)\n",
    "\n",
    "assert torch.allclose(ori_encoded, modded_encoded)\n",
    "assert torch.allclose(ori_encoded, scripted_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple decoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50359, 50363]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is <|startoftranscript|><|en|><|transcribe|><|notimestamps|> from gpt2 tokenizer\n",
    "tokens = torch.tensor([50258, 50259, 50359, 50363]).unsqueeze(0)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_decoded = ori.decoder(tokens, ori_encoded)\n",
    "modded_decoded = modded.decoder(tokens, ori_encoded, {})\n",
    "scripted_decoded = scripted.decoder(tokens, ori_encoded, {})\n",
    "\n",
    "assert torch.allclose(ori_decoded, modded_decoded)\n",
    "assert torch.allclose(ori_decoded, scripted_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='whisper/assets/whisper_mult_gpt2', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'additional_special_tokens': ['<|startoftranscript|>', '<|en|>', '<|zh|>', '<|de|>', '<|es|>', '<|ru|>', '<|ko|>', '<|fr|>', '<|ja|>', '<|pt|>', '<|tr|>', '<|pl|>', '<|ca|>', '<|nl|>', '<|ar|>', '<|sv|>', '<|it|>', '<|id|>', '<|hi|>', '<|fi|>', '<|vi|>', '<|iw|>', '<|uk|>', '<|el|>', '<|ms|>', '<|cs|>', '<|ro|>', '<|da|>', '<|hu|>', '<|ta|>', '<|no|>', '<|th|>', '<|ur|>', '<|hr|>', '<|bg|>', '<|lt|>', '<|la|>', '<|mi|>', '<|ml|>', '<|cy|>', '<|sk|>', '<|te|>', '<|fa|>', '<|lv|>', '<|bn|>', '<|sr|>', '<|az|>', '<|sl|>', '<|kn|>', '<|et|>', '<|mk|>', '<|br|>', '<|eu|>', '<|is|>', '<|hy|>', '<|ne|>', '<|mn|>', '<|bs|>', '<|kk|>', '<|sq|>', '<|sw|>', '<|gl|>', '<|mr|>', '<|pa|>', '<|si|>', '<|km|>', '<|sn|>', '<|yo|>', '<|so|>', '<|af|>', '<|oc|>', '<|ka|>', '<|be|>', '<|tg|>', '<|sd|>', '<|gu|>', '<|am|>', '<|yi|>', '<|lo|>', '<|uz|>', '<|fo|>', '<|ht|>', '<|ps|>', '<|tk|>', '<|nn|>', '<|mt|>', '<|sa|>', '<|lb|>', '<|my|>', '<|bo|>', '<|tl|>', '<|mg|>', '<|as|>', '<|tt|>', '<|haw|>', '<|ln|>', '<|ha|>', '<|ba|>', '<|jw|>', '<|su|>', '<|translate|>', '<|transcribe|>', '<|startoflm|>', '<|startofprev|>', '<|nospeech|>', '<|notimestamps|>']})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the already built tokenizer, no need to add manually\n",
    "# only works for multilingual for now\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"whisper/assets/whisper_mult_gpt2\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppressed tokens, see SuppressBlank and SuppressTokens class\n",
    "suppress_blanks = [220, 50257]\n",
    "suppress_nonspeech = [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, \n",
    "    93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, \n",
    "    3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, \n",
    "    14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, \n",
    "    32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[50258, 50259, 50359, 50363]]), torch.Size([1, 4]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode(\"<|startoftranscript|><|en|><|transcribe|><|notimestamps|>\", return_tensors=\"pt\")\n",
    "tokens, tokens.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And so my fellow Americans, ask not what your country can do for you, ask what you can do for your country.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = whisper.DecodingOptions(language=\"en\", fp16=False)\n",
    "ori_transcribed = whisper.decode(ori, mel, options)\n",
    "ori_transcribed[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' And so my fellow Americans, ask not what your country can do for you, ask what you can do for your country.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modded_transcribed = modded.greedy_decode(tokens, mel, suppress_blanks, suppress_nonspeech)\n",
    "tokenizer.batch_decode(modded_transcribed, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61806/3722662783.py:1: UserWarning: operator() sees varying value in profiling, ignoring and this should be handled by GUARD logic (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484806139/work/torch/csrc/jit/codegen/cuda/parser.cpp:3513.)\n",
      "  scripted_transcribed = scripted.greedy_decode(tokens, mel, suppress_blanks, suppress_nonspeech)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' And so my fellow Americans, ask not what your country can do for you, ask what you can do for your country.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripted_transcribed = scripted.greedy_decode(tokens, mel, suppress_blanks, suppress_nonspeech)\n",
    "tokenizer.batch_decode(scripted_transcribed, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummy(nn.Module):\n",
    "    \n",
    "    def __init__(self, keygen: Generator) -> None:\n",
    "        super().__init__()\n",
    "        self.unique_num = next(keygen)\n",
    "        self.unique_num = next(keygen)\n",
    "        self.lin = nn.Linear(4, 4)\n",
    "    \n",
    "    def forward(self, x: Tensor, cache: dict[int, Tensor]):\n",
    "        if self.unique_num not in cache:\n",
    "            cache[self.unique_num] = self.lin(x)\n",
    "        return cache[self.unique_num]\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def generate(self, x: Tensor):\n",
    "        print(self.unique_num)\n",
    "        cache: dict[int, Tensor] = {}\n",
    "        a = self.forward(x, cache)\n",
    "        b = self.forward(x*2, cache)\n",
    "        return a-b\n",
    "\n",
    "keygen = itertools.count()\n",
    "dummy = Dummy(keygen)\n",
    "sdummy = torch.jit.script(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.generate(torch.randn(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdummy.generate(torch.randn(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'bool' as child module 'training' (torch.nn.Module or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/evan/Documents/whisper-torchscript/tests.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evan/Documents/whisper-torchscript/tests.ipynb#Y134sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/evan/Documents/whisper-torchscript/tests.ipynb#Y134sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m net \u001b[39m=\u001b[39m Net()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/evan/Documents/whisper-torchscript/tests.ipynb#Y134sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m net\u001b[39m.\u001b[39;49meval()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1858\u001b[0m, in \u001b[0;36mModule.eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval\u001b[39m(\u001b[39mself\u001b[39m: T) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m   1843\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sets the module in evaluation mode.\u001b[39;00m\n\u001b[1;32m   1844\u001b[0m \n\u001b[1;32m   1845\u001b[0m \u001b[39m    This has any effect only on certain modules. See documentations of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1856\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1858\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1837\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(mode, \u001b[39mbool\u001b[39m):\n\u001b[1;32m   1836\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mtraining mode is expected to be boolean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1837\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m mode\n\u001b[1;32m   1838\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m   1839\u001b[0m     module\u001b[39m.\u001b[39mtrain(mode)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1242\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[39melif\u001b[39;00m modules \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1241\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1242\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot assign \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m as child module \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1243\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39m(torch.nn.Module or None expected)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1244\u001b[0m                         \u001b[39m.\u001b[39mformat(torch\u001b[39m.\u001b[39mtypename(value), name))\n\u001b[1;32m   1245\u001b[0m     modules[name] \u001b[39m=\u001b[39m value\n\u001b[1;32m   1246\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot assign 'bool' as child module 'training' (torch.nn.Module or None expected)"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.training = nn.Linear(5, 4)  # hmm\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c788065d0627783e03f01588c616fdc081ccf79059243dc851e48ed3fc07eef9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
